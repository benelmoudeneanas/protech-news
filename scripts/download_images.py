#!/usr/bin/env python3
"""
Image Downloader for ProTech News with WebP Conversion
ÙŠÙ‚Ø±Ø£ Ø§Ù„ØµÙˆØ± Ù…Ù† data.jsØŒ ÙŠØ­Ù…Ù„Ù‡Ø§ØŒ ÙŠØ­ÙˆÙ„Ù‡Ø§ Ù„Ù€ WebPØŒ ÙˆÙŠØ®Ø²Ù†Ù‡Ø§ Ù…Ø­Ù„ÙŠØ§Ù‹
"""

import os
import re
import hashlib
import requests
from urllib.parse import urlparse
from pathlib import Path
from PIL import Image
from io import BytesIO

# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
DATA_JS_PATH = "assets/js/data.js"
IMAGES_DIR = "assets/images/articles"
TEMP_DATA_JS = "assets/js/data.js.backup"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª WebP
CONVERT_TO_WEBP = True  # â† ØºÙŠØ±Ù‡Ø§ Ù„Ù€ False Ø¥Ø°Ø§ Ù…Ø§ Ø¨ØºÙŠØªÙŠØ´ WebP
WEBP_QUALITY = 85  # Ø¬ÙˆØ¯Ø© WebP (1-100ØŒ 85 Ù…Ù…ØªØ§Ø²)
MAX_WIDTH = 800  # Ø£Ù‚ØµÙ‰ Ø¹Ø±Ø¶ Ù„Ù„ØµÙˆØ± (Ø¨Ø§Ø´ ÙŠØµØºØ±ÙˆØ§ Ø¥Ù„Ø§ ÙƒØ§Ù†Ùˆ ÙƒØ¨Ø§Ø± Ø¨Ø²Ø§Ù)

def ensure_directories():
    """Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª"""
    os.makedirs(IMAGES_DIR, exist_ok=True)

def parse_data_js():
    """Ù‚Ø±Ø§Ø¡Ø© ÙˆØªØ­Ù„ÙŠÙ„ data.js Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±"""

    with open(DATA_JS_PATH, 'r', encoding='utf-8') as f:
        content = f.read()

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØµÙˆØ±
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: img: "https://..." Ø£Ùˆ img: 'https://...'
    img_pattern = r'img\s*:\s*["\']([^"\']+)["\']'
    images = re.findall(img_pattern, content)

    return content, images

def generate_local_filename(url, force_webp=False):
    """ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ù…Ù„Ù Ù…Ø­Ù„ÙŠ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
    # Ø§Ø³ØªØ¹Ù…Ø§Ù„ hash Ø¨Ø§Ø´ Ù†ØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
    url_hash = hashlib.md5(url.encode()).hexdigest()[:12]

    # Ø¥Ø°Ø§ Ø¨ØºÙŠÙ†Ø§ Ù†Ø­ÙˆÙ„ÙˆØ§ Ù„Ù€ WebP
    if CONVERT_TO_WEBP or force_webp:
        ext = '.webp'
    else:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠ
        parsed = urlparse(url)
        path = parsed.path
        ext = os.path.splitext(path)[1]

        # Ø¥Ø°Ø§ Ù…Ø§ÙÙŠÙ‡Ø´ Ø§Ù…ØªØ¯Ø§Ø¯ØŒ Ø§Ø³ØªØ¹Ù…Ù„ .jpg ÙƒØ§ÙØªØ±Ø§Ø¶ÙŠ
        if not ext or ext not in ['.jpg', '.jpeg', '.png', '.webp', '.gif']:
            ext = '.jpg'

    return f"article-{url_hash}{ext}"

def convert_to_webp(image_data, save_path):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ WebP Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ø¬Ù…"""
    try:
        # ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        img = Image.open(BytesIO(image_data))

        # ØªØ­ÙˆÙŠÙ„ RGBA Ø¥Ù„Ù‰ RGB Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
        if img.mode in ('RGBA', 'LA', 'P'):
            # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ù„ÙÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡
            background = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
            img = background
        elif img.mode != 'RGB':
            img = img.convert('RGB')

        # ØªØµØºÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙƒØ¨ÙŠØ±Ø© Ø¨Ø²Ø§Ù
        if img.width > MAX_WIDTH:
            ratio = MAX_WIDTH / img.width
            new_height = int(img.height * ratio)
            img = img.resize((MAX_WIDTH, new_height), Image.Resampling.LANCZOS)
            print(f"      ğŸ“ ØªØµØºÙŠØ±: {img.width}x{img.height}")

        # Ø­ÙØ¸ ÙƒÙ€ WebP
        img.save(save_path, 'WEBP', quality=WEBP_QUALITY, method=6)

        return True

    except Exception as e:
        print(f"      âŒ ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù€ WebP: {str(e)[:50]}")
        return False

def download_and_convert_image(url, save_path):
    """ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ù€ WebP"""
    try:
        print(f"      â¬‡ï¸  ØªØ­Ù…ÙŠÙ„: {url[:60]}...")

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        response = requests.get(url, headers=headers, timeout=30, stream=True)
        response.raise_for_status()

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        image_data = response.content
        original_size = len(image_data) / 1024  # KB

        print(f"      ğŸ“¥ Ø­Ø¬Ù… Ø£ØµÙ„ÙŠ: {original_size:.1f} KB")

        # Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù€ WebP
        if CONVERT_TO_WEBP:
            if convert_to_webp(image_data, save_path):
                webp_size = os.path.getsize(save_path) / 1024  # KB
                savings = ((original_size - webp_size) / original_size) * 100
                print(f"      âœ… WebP: {webp_size:.1f} KB (ØªÙˆÙÙŠØ± {savings:.0f}%)")
                return True
            else:
                # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ØŒ Ø§Ø­ÙØ¸Ù‡Ø§ ÙƒÙ…Ø§ Ù‡ÙŠ
                print(f"      âš ï¸  Ø§Ù„Ø­ÙØ¸ Ø¨Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ø£ØµÙ„ÙŠØ©...")
                with open(save_path, 'wb') as f:
                    f.write(image_data)
                return True
        else:
            # Ø­ÙØ¸ Ø¨Ø¯ÙˆÙ† ØªØ­ÙˆÙŠÙ„
            with open(save_path, 'wb') as f:
                f.write(image_data)
            print(f"      âœ… ØªÙ… Ø§Ù„Ø­ÙØ¸: {original_size:.1f} KB")
            return True

    except requests.exceptions.RequestException as e:
        print(f"      âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {str(e)[:50]}")
        return False
    except Exception as e:
        print(f"      âŒ Ø®Ø·Ø£: {str(e)[:50]}")
        return False

def process_images():
    """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ±"""

    ensure_directories()

    # Ù‚Ø±Ø§Ø¡Ø© data.js
    content, images = parse_data_js()

    if not images:
        print("âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙˆØ± ÙÙŠ data.js")
        return

    print(f"\nğŸ“Š ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(images)} ØµÙˆØ±Ø©")
    if CONVERT_TO_WEBP:
        print(f"ğŸ”„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù€ WebP Ù…ÙØ¹Ù„ (Ø¬ÙˆØ¯Ø©: {WEBP_QUALITY}%)")
    print("=" * 70)

    # Ø®Ø±ÙŠØ·Ø© Ù„Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„ (Ø±Ø§Ø¨Ø· Ù‚Ø¯ÙŠÙ… -> Ø±Ø§Ø¨Ø· Ø¬Ø¯ÙŠØ¯)
    replacements = {}
    downloaded = 0
    skipped = 0
    failed = 0
    total_original_size = 0
    total_webp_size = 0

    for i, img_url in enumerate(images, 1):
        print(f"\n[{i}/{len(images)}] Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©...")

        # ØªØ¬Ù†Ø¨ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        if img_url.startswith('../') or img_url.startswith('assets/'):
            print(f"      â­ï¸  ØªØ®Ø·ÙŠ: ØµÙˆØ±Ø© Ù…Ø­Ù„ÙŠØ© Ø¨Ø§Ù„ÙØ¹Ù„")
            skipped += 1
            continue

        # ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ
        local_filename = generate_local_filename(img_url)
        local_path = os.path.join(IMAGES_DIR, local_filename)

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹
        if os.path.exists(local_path):
            print(f"      âœ… Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹: {local_filename}")
            skipped += 1
        else:
            # ØªØ­Ù…ÙŠÙ„ ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            if download_and_convert_image(img_url, local_path):
                downloaded += 1
            else:
                failed += 1
                continue

        # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ø§Øª
        # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ø³Ø¨ÙŠ Ù…Ù† root: assets/images/articles/xxx.webp
        new_url = f"assets/images/articles/{local_filename}"
        replacements[img_url] = new_url

    print("\n" + "=" * 70)
    print(f"ğŸ“¦ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù…ÙŠÙ„:")
    print(f"   âœ… ØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„: {downloaded}")
    print(f"   â­ï¸  Ù…ØªØ®Ø·Ø§Ø©: {skipped}")
    print(f"   âŒ ÙØ´Ù„Øª: {failed}")
    print(f"   ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {len(images)}")

    if CONVERT_TO_WEBP and downloaded > 0:
        print(f"\nğŸ’¾ ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ WebP Ø¨Ø¬ÙˆØ¯Ø© {WEBP_QUALITY}%")

    return content, replacements

def update_data_js(content, replacements):
    """ØªØ­Ø¯ÙŠØ« data.js Ø¨Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©"""

    if not replacements:
        print("\nâš ï¸  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ø§Øª Ù„Ù„ØªØ·Ø¨ÙŠÙ‚")
        return

    print("\n" + "=" * 70)
    print("ğŸ”„ ØªØ­Ø¯ÙŠØ« data.js...")

    # Ø­ÙØ¸ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
    backup_path = DATA_JS_PATH + ".backup"
    with open(DATA_JS_PATH, 'r', encoding='utf-8') as f:
        with open(backup_path, 'w', encoding='utf-8') as bf:
            bf.write(f.read())

    print(f"   ğŸ’¾ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_path}")

    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    updated_content = content
    replaced_count = 0

    for old_url, new_url in replacements.items():
        if old_url in updated_content:
            updated_content = updated_content.replace(old_url, new_url)
            replaced_count += 1
            print(f"   âœ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„: {os.path.basename(new_url)}")

    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ø¯Ø«
    with open(DATA_JS_PATH, 'w', encoding='utf-8') as f:
        f.write(updated_content)

    print(f"\n   âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« {replaced_count} Ø±Ø§Ø¨Ø· ÙÙŠ data.js")

def main():
    """Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""

    print("=" * 70)
    print("ğŸ–¼ï¸  ProTech Image Downloader & WebP Converter")
    print("=" * 70)

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ data.js
    if not os.path.exists(DATA_JS_PATH):
        print(f"âŒ {DATA_JS_PATH} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return

    try:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±
        content, replacements = process_images()

        # ØªØ­Ø¯ÙŠØ« data.js
        if replacements:
            update_data_js(content, replacements)

        print("\n" + "=" * 70)
        print("âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­!")
        print("=" * 70)
        print("\nğŸ’¡ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:")
        print("   1. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯: assets/images/articles/")
        print("   2. Ø±Ø§Ø¬Ø¹ data.js (Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: data.js.backup)")
        print("   3. Ø´ØºÙ„ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù…ÙˆÙ„Ø¯: python3 scripts/auto_generate_from_data.py")
        print("   4. Commit & Push Ù„Ù„ØªØºÙŠÙŠØ±Ø§Øª")

        if CONVERT_TO_WEBP:
            print(f"\nğŸ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± ØªÙ… ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ù€ WebP Ø¨Ø¬ÙˆØ¯Ø© {WEBP_QUALITY}%")

    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()