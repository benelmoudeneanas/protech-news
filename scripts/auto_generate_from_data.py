#!/usr/bin/env python3
"""
Auto Generate Articles from data.js (UPDATED)
ÙŠÙ‚Ø±Ø£ data.js ÙˆÙŠÙˆÙ„Ø¯ Ù…Ù„ÙØ§Øª HTML Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­Ù„ÙŠØ©
"""

import os
import re
from datetime import datetime

# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
DATA_JS_PATH = "assets/js/data.js"
TEMPLATE_PATH = "templates/article-template.html"
ARTICLES_DIR = "articles"
BASE_URL = "https://protechdaily.online"

def parse_data_js():
    """Ù‚Ø±Ø§Ø¡Ø© ÙˆØªØ­Ù„ÙŠÙ„ data.js"""
    
    with open(DATA_JS_PATH, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ array Ù…Ù† JavaScript
    match = re.search(r'const\s+articles\s*=\s*\[(.*?)\];', content, re.DOTALL)
    
    if not match:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ articles array ÙÙŠ data.js")
        return []
    
    array_content = match.group(1)
    articles = []
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª (ÙƒÙ„ object Ø¨ÙŠÙ† {})
    pattern = r'\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}'
    objects = re.findall(pattern, array_content)
    
    for obj in objects:
        article = {}
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
        fields = ['slug', 'title', 'date', 'cat', 'desc', 'img', 'url']
        
        for field in fields:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: field: "value" Ø£Ùˆ field: 'value'
            field_pattern = rf'{field}\s*:\s*["\']([^"\']*)["\']'
            field_match = re.search(field_pattern, obj)
            if field_match:
                article[field] = field_match.group(1).replace('\\', '')
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ content (Ø¨ÙŠÙ† ` `)
        content_match = re.search(r'content\s*:\s*`([^`]+)`', obj, re.DOTALL)
        if content_match:
            article['content'] = content_match.group(1).strip()
        
        if article.get('slug'):
            articles.append(article)
    
    return articles

def format_date(date_str):
    """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ø±ÙŠØ®"""
    try:
        date_obj = datetime.strptime(date_str, "%Y-%m-%d")
        return date_obj.strftime("%B %d, %Y")
    except:
        return date_str

def get_category_class(category):
    """CSS class Ù„Ù„ÙØ¦Ø©"""
    category_map = {
        'ios': 'cat-ios',
        'ai': 'cat-ai',
        'leaks': 'cat-leaks',
        'hardware': 'cat-hardware',
        'gaming': 'cat-gaming',
        'tech': 'cat-tech',
        'news': 'cat-tech',
        'reviews': 'cat-tech',
        'comparison': 'cat-tech',
        'tech-tips': 'cat-tech',
        'entertainment': 'cat-entertainment'
    }
    return category_map.get(category.lower(), 'cat-tech')

def convert_image_path(img_url):
    """ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ù…Ø·Ù„Ù‚ Ø¥Ù„Ù‰ Ù†Ø³Ø¨ÙŠ"""
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© Ù…Ø­Ù„ÙŠØ© Ø¨Ø§Ù„ÙØ¹Ù„
    if img_url.startswith('assets/'):
        # Ù…Ù† articles/ Ù†Ø±Ø¬Ø¹ Ù„Ù€ root ÙˆÙ†Ø±ÙˆØ­ Ù„Ù€ assets
        return f"../{img_url}"
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø±Ø§Ø¨Ø· Ø®Ø§Ø±Ø¬ÙŠØŒ Ù†Ø®Ù„ÙŠÙ‡Ø§ ÙƒÙ…Ø§ Ù‡ÙŠ
    # (Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø¢Ø®Ø± download_images.py ÙŠØ­ÙˆÙ„Ù‡Ø§ Ù„Ù…Ø­Ù„ÙŠØ©)
    return img_url

def get_article_content(article_data):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ - Ù…Ù† data.js Ø£Ùˆ ØªÙˆÙ„ÙŠØ¯ Ø¨Ø³ÙŠØ·"""
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ data.jsØŒ Ø§Ø³ØªØ¹Ù…Ù„Ù‡
    if article_data.get('content'):
        content = article_data['content']
        
        # ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØµÙˆØ± ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† src="assets/images/..." ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ù€ src="../assets/images/..."
        content = re.sub(
            r'src="(assets/images/[^"]+)"',
            r'src="../\1"',
            content
        )
        
        return content
    
    # Ø¥Ø°Ø§ Ù…Ø§ÙÙŠÙ‡Ø´ØŒ ÙˆÙ„Ø¯ Ù…Ø­ØªÙˆÙ‰ Ø¨Ø³ÙŠØ·
    desc = article_data.get('desc', '')
    
    return f'''
        <h2>Overview</h2>
        <p>{desc}</p>
        
        <p>This article will be updated with full content soon. Stay tuned for more details!</p>
    '''

def generate_article_html(article_data):
    """ØªÙˆÙ„ÙŠØ¯ HTML Ù…Ù† Ø§Ù„Ù‚Ø§Ù„Ø¨"""
    
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù‚Ø§Ù„Ø¨
    with open(TEMPLATE_PATH, 'r', encoding='utf-8') as f:
        template = f.read()
    
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    article_content = get_article_content(article_data)
    
    # ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©
    article_image = convert_image_path(article_data.get('img', ''))
    
    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    replacements = {
        '{{TITLE}}': article_data.get('title', 'Untitled'),
        '{{DESCRIPTION}}': article_data.get('desc', ''),
        '{{KEYWORDS}}': article_data.get('title', ''),
        '{{CANONICAL_URL}}': f"{BASE_URL}/articles/{article_data.get('slug', '')}.html",
        '{{IMAGE}}': article_image,  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­ÙˆÙ„
        '{{DATE}}': article_data.get('date', datetime.now().strftime('%Y-%m-%d')),
        '{{DATE_FORMATTED}}': format_date(article_data.get('date', '')),
        '{{CATEGORY}}': article_data.get('cat', 'tech').upper(),
        '{{CATEGORY_CLASS}}': get_category_class(article_data.get('cat', 'tech')),
        '{{TITLE_SHORT}}': article_data.get('title', '')[:50] + '...' if len(article_data.get('title', '')) > 50 else article_data.get('title', ''),
        '{{CONTENT}}': article_content
    }
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ø§Øª
    html = template
    for placeholder, value in replacements.items():
        html = html.replace(placeholder, str(value))
    
    return html

def main():
    """Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    
    print("ğŸ¤– Auto Generate Articles from data.js (UPDATED)")
    print("=" * 60)
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª
    if not os.path.exists(DATA_JS_PATH):
        print(f"âŒ {DATA_JS_PATH} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return
    
    if not os.path.exists(TEMPLATE_PATH):
        print(f"âŒ {TEMPLATE_PATH} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return
    
    if not os.path.exists(ARTICLES_DIR):
        os.makedirs(ARTICLES_DIR)
    
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ù…Ù† data.js
    articles = parse_data_js()
    
    if not articles:
        print("âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù‚Ø§Ù„Ø§Øª ÙÙŠ data.js")
        return
    
    print(f"\nğŸ“Š ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(articles)} Ù…Ù‚Ø§Ù„ ÙÙŠ data.js")
    
    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
    new_count = 0
    skipped_count = 0
    
    for article in articles:
        slug = article.get('slug', '')
        if not slug:
            continue
        
        article_path = os.path.join(ARTICLES_DIR, f"{slug}.html")
        
        # ØªÙˆÙ„ÙŠØ¯ HTML
        html = generate_article_html(article)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
        if os.path.exists(article_path):
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
            with open(article_path, 'r', encoding='utf-8') as f:
                existing = f.read()
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù‚Ø¯ÙŠÙ… Ø£Ùˆ placeholder
            if 'Content coming soon' in existing or 'will be updated with full content soon' in existing or len(existing) < 3000:
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ù
                with open(article_path, 'w', encoding='utf-8') as f:
                    f.write(html)
                print(f"   ğŸ”„ Ù…Ø­Ø¯Ø«: {slug}.html")
                new_count += 1
            else:
                # ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ ÙƒØ§Ù…Ù„
                print(f"   â­ï¸  ØªØ®Ø·ÙŠ: {slug}.html (ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰)")
                skipped_count += 1
        else:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯
            with open(article_path, 'w', encoding='utf-8') as f:
                f.write(html)
            print(f"   âœ… Ø¬Ø¯ÙŠØ¯: {slug}.html")
            new_count += 1
    
    print("\n" + "=" * 60)
    print(f"âœ… ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"   - Ù…Ù‚Ø§Ù„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©/Ù…Ø­Ø¯Ø«Ø©: {new_count}")
    print(f"   - Ù…Ù‚Ø§Ù„Ø§Øª Ù…ØªØ®Ø·Ø§Ø©: {skipped_count}")
    print(f"   - Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {len(articles)}")
    print("\nğŸ’¡ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­Ù„ÙŠØ© ÙÙŠ assets/images/articles/")

if __name__ == "__main__":
    main()
